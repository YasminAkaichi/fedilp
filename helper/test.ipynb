{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yakaichi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Text representing logic clauses\n",
    "text = \"\"\"\n",
    "Clauses:\n",
    "   parent(A, B) :- mother(A, B).\n",
    "   parent(A, B) :- father(A, B).\n",
    "   grandfather(A, B) :- father(A, C), parent(C, B).\n",
    "   grandparent(A, B) :- parent(A, C), parent(C, B).\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the text using a transformer tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "# Convert tokens to PyTorch tensor\n",
    "tensor = torch.tensor(tokens)\n",
    "\n",
    "# Convert PyTorch tensor back to tokens\n",
    "tokens_back = tensor.tolist()\n",
    "\n",
    "# Decode tokens to text\n",
    "text_back = tokenizer.decode(tokens_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  198, 47404,  2664,    25,   198,   220,   220,  2560,     7,    32,\n",
       "           11,   347,     8,  1058,    12,  2802,     7,    32,    11,   347,\n",
       "          737,   198,   220,   220,  2560,     7,    32,    11,   347,     8,\n",
       "         1058,    12,  2988,     7,    32,    11,   347,   737,   198,   220,\n",
       "          220, 17695,     7,    32,    11,   347,     8,  1058,    12,  2988,\n",
       "            7,    32,    11,   327,   828,  2560,     7,    34,    11,   347,\n",
       "          737,   198,   220,   220,  4490,  8000,     7,    32,    11,   347,\n",
       "            8,  1058,    12,  2560,     7,    32,    11,   327,   828,  2560,\n",
       "            7,    34,    11,   347,   737,   198])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nClauses:\\n   parent(A, B) :- mother(A, B).\\n   parent(A, B) :- father(A, B).\\n   grandfather(A, B) :- father(A, C), parent(C, B).\\n   grandparent(A, B) :- parent(A, C), parent(C, B).\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "value = '[person(andrew)., person(bernard)., person(cathleen)., person(daphne)., person(edith)., person(fred)., person(george)., person(john)., person(louis)., person(oscar)., person(paul)., person(robert)., person(stephen)., person(sylvia)., person(william)., person(ada)., father(william, sylvia)., father(oscar, louis)., father(oscar, daphne)., father(oscar, cathleen)., father(oscar, fred)., father(oscar, bernard)., father(louis, stephen)., father(louis, andrew)., father(louis, robert)., father(louis, john)., father(george, oscar)., father(paul, edith)., mother(sylvia, stephen)., mother(sylvia, andrew)., mother(sylvia, robert)., mother(sylvia, john)., mother(edith, louis)., mother(edith, daphne)., mother(edith, cathleen)., mother(edith, fred)., mother(edith, bernard)., mother(ada, sylvia)., parent(A, B) :- mother(A, B)., parent(A, B) :- father(A, B)., grandfather(A, B) :- father(A, C), parent(C, B)., grandparent(A, B) :- parent(A, C), parent(C, B).])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andante.collections import OrderedSet\n",
    "from typing import Union\n",
    "\n",
    "def get_tensor(rules:Union[str,OrderedSet]):\n",
    "    # Tokenize the text using a transformer tokenizer\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    if isinstance(rules,str):\n",
    "        tokens = tokenizer.encode(text) \n",
    "    elif isinstance(rules,OrderedSet):\n",
    "        text = \"\\n\".join([f\"{k}: {v}\" for k, v in rules.items()])\n",
    "        tokens = tokenizer.encode(text)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a string or an OrderedDict\")\n",
    "    # Convert tokens to PyTorch tensor\n",
    "    tensor = torch.tensor(tokens)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
